# Project Transformation Plan: Simplified RAG Class Platform

## Executive Summary

Transform the current WordWyrm/Greek Demo project into a streamlined RAG-based learning platform where:
- Teachers create classes and upload materials
- Materials are automatically vectorized using OpenAI embeddings
- Students chat with an AI that has access to ALL class materials via RAG
- Teachers view student chat history to identify learning gaps

**Recommendation: Strip down the existing project** rather than starting fresh.

---

## 1. Should You Start Fresh or Strip Down?

### Recommendation: **Strip Down the Existing Project** ‚úÖ

**Why:**
1. ‚úÖ **Auth is already working** - NextAuth v5 with role-based access (Teacher/Student)
2. ‚úÖ **Class management exists** - Create, list, manage classes
3. ‚úÖ **Database connection is set up** - Vercel Postgres (Neon) already configured
4. ‚úÖ **File upload infrastructure** - Vercel Blob integration works
5. ‚úÖ **Chat conversation schema** - Already has classId context
6. ‚è±Ô∏è **Time savings** - 60-70% of foundation is reusable
7. üéØ **Lower risk** - Proven components vs. starting from scratch

**What You'll Remove:**
- ‚ùå Lessons, Lesson-Class relationships
- ‚ùå Packets, PacketItems, PacketVersions
- ‚ùå ProcessedContent (replace with vector chunks)
- ‚ùå Materials (flashcards, worksheets, summaries)
- ‚ùå ClassMaterial relationships
- ‚ùå Invite codes (unless you want to keep for student enrollment)
- ‚ùå All generation actions (flashcard, worksheet, summary)
- ‚ùå All lesson/packet UI pages

**What You'll Keep:**
- ‚úÖ User, Class, ClassMembership models
- ‚úÖ Authentication system (NextAuth)
- ‚úÖ Class creation/management UI
- ‚úÖ ChatConversation, ChatMessage models (simplified)
- ‚úÖ File upload infrastructure (modify for any file type)
- ‚úÖ Teacher dashboard structure
- ‚úÖ Student dashboard structure

---

## 2. Vector Database Decision

### Recommendation: **pgvector (PostgreSQL extension)** ‚úÖ

**Why pgvector:**
1. ‚úÖ **Already using PostgreSQL** - No new database service
2. ‚úÖ **Neon (Vercel Postgres) supports pgvector** - Built-in support
3. ‚úÖ **Simplified architecture** - One database for all data
4. ‚úÖ **Cost-effective** - No additional service fees
5. ‚úÖ **Good for MVP scale** - Handles 100k+ vectors easily
6. ‚úÖ **SQL familiarity** - Use Prisma + raw SQL for vector operations
7. ‚úÖ **Transactional integrity** - Files and embeddings in same DB

**Alternatives Considered:**
- **Pinecone**: Great for production scale, but adds $70+/month and extra complexity
- **Weaviate**: Powerful but overkill for MVP, requires self-hosting or cloud service
- **Supabase**: Good option if switching, but Vercel Postgres is already working

**pgvector Setup:**
```sql
-- Enable extension (run once)
CREATE EXTENSION IF NOT EXISTS vector;

-- Vector similarity search (example)
SELECT id, content, 1 - (embedding <=> $1::vector) AS similarity
FROM file_chunks
WHERE class_id = $2
ORDER BY embedding <=> $1::vector
LIMIT 10;
```

---

## 3. Simplified Database Schema

### New Schema (8 models, down from 15)

```prisma
// Keep as-is
model User {
  id           String    @id @default(cuid())
  email        String    @unique
  passwordHash String
  name         String?
  role         Role      @default(STUDENT)
  createdAt    DateTime  @default(now())
  updatedAt    DateTime  @updatedAt

  // Relations
  teacherClasses   Class[]              @relation("TeacherClasses")
  memberships      ClassMembership[]
  conversations    ChatConversation[]

  @@index([email])
  @@index([role])
}

enum Role {
  TEACHER
  STUDENT
  ADMIN
}

// Simplified - remove all lesson/packet references
model Class {
  id          String   @id @default(cuid())
  name        String
  description String?
  isActive    Boolean  @default(true)
  teacherId   String
  inviteCode  String   @unique  // Optional: keep if you want easy enrollment
  createdAt   DateTime @default(now())
  updatedAt   DateTime @updatedAt

  // Relations
  teacher      User                 @relation("TeacherClasses", fields: [teacherId], references: [id], onDelete: Cascade)
  memberships  ClassMembership[]
  files        ClassFile[]
  conversations ChatConversation[]

  @@index([teacherId])
  @@index([inviteCode])
  @@index([isActive])
}

// Keep as-is
model ClassMembership {
  id        String   @id @default(cuid())
  classId   String
  userId    String
  joinedAt  DateTime @default(now())

  // Relations
  class Class @relation(fields: [classId], references: [id], onDelete: Cascade)
  user  User  @relation(fields: [userId], references: [id], onDelete: Cascade)

  @@unique([classId, userId])
  @@index([userId])
}

// NEW - Uploaded files (PDFs, DOCX, TXT, etc.)
model ClassFile {
  id          String   @id @default(cuid())
  classId     String
  fileName    String
  fileType    String   // "application/pdf", "text/plain", etc.
  fileSize    Int      // bytes
  blobUrl     String   // Vercel Blob URL
  uploadedBy  String   // userId
  status      FileProcessingStatus @default(PENDING)
  errorMessage String? // if processing fails
  createdAt   DateTime @default(now())
  updatedAt   DateTime @updatedAt

  // Relations
  class  Class       @relation(fields: [classId], references: [id], onDelete: Cascade)
  chunks FileChunk[]

  @@index([classId])
  @@index([status])
}

enum FileProcessingStatus {
  PENDING
  PROCESSING
  COMPLETED
  FAILED
}

// NEW - Vectorized chunks of files
model FileChunk {
  id         String                 @id @default(cuid())
  fileId     String
  classId    String                 // Denormalized for faster queries
  content    String                 @db.Text  // The actual text chunk
  embedding  Unsupported("vector(1536)")  // OpenAI text-embedding-3-small dimension
  chunkIndex Int                    // Order within file
  metadata   Json?                  // Page number, section, etc.
  createdAt  DateTime               @default(now())

  // Relations
  file ClassFile @relation(fields: [fileId], references: [id], onDelete: Cascade)

  @@index([fileId])
  @@index([classId])
  // Vector index (create with raw SQL after migration)
  // CREATE INDEX ON file_chunks USING ivfflat (embedding vector_cosine_ops) WITH (lists = 100);
}

// Simplified - only classId context (no materialId, no lessonId)
model ChatConversation {
  id        String   @id @default(cuid())
  userId    String   // Student
  classId   String   // Which class context
  title     String   @default("New Conversation")
  createdAt DateTime @default(now())
  updatedAt DateTime @updatedAt

  // Relations
  user     User          @relation(fields: [userId], references: [id], onDelete: Cascade)
  class    Class         @relation(fields: [classId], references: [id], onDelete: Cascade)
  messages ChatMessage[]

  @@index([userId])
  @@index([classId, createdAt])  // For teacher insights
  @@index([userId, classId])
}

// Keep as-is
model ChatMessage {
  id             String   @id @default(cuid())
  conversationId String
  role           String   // "user" or "assistant"
  content        String   @db.Text
  createdAt      DateTime @default(now())

  // Relations
  conversation ChatConversation @relation(fields: [conversationId], references: [id], onDelete: Cascade)

  @@index([conversationId])
}
```

**Key Changes:**
1. ‚ùå Removed: Lesson, LessonClass, Packet, PacketItem, PacketVersion, PacketOpenTab, PDF, ProcessedContent, Material, ClassMaterial
2. ‚úÖ Added: ClassFile (replaces PDF), FileChunk (replaces ProcessedContent)
3. ‚úÖ Simplified: ChatConversation only has classId (no materialId)
4. ‚úÖ Vector embeddings: FileChunk has `vector(1536)` column for pgvector
5. ‚úÖ File status tracking: PENDING ‚Üí PROCESSING ‚Üí COMPLETED/FAILED

---

## 4. OpenAI Integration Architecture

### 4.1 Embedding Model

**Recommended: `text-embedding-3-small`**
- Dimensions: 1536 (default)
- Cost: $0.02 per 1M tokens (~$0.00002 per 1k tokens)
- Speed: ~100ms per request
- Quality: Excellent for most use cases

**Alternative: `text-embedding-3-large`** (if you need higher accuracy)
- Dimensions: 3072
- Cost: $0.13 per 1M tokens
- Better semantic understanding, but 6.5x more expensive

### 4.2 Chat Model

**Recommended: `gpt-4o-mini`** (for cost efficiency)
- Cost: $0.150 per 1M input tokens, $0.600 per 1M output tokens
- Fast and capable for RAG Q&A

**Alternative: `gpt-4-turbo`** (for better reasoning)
- Cost: $10 per 1M input tokens, $30 per 1M output tokens
- Use if students need deep analysis

### 4.3 Chunking Strategy

**Recommended Approach:**
```typescript
// Chunk size: 500-1000 tokens (~2000-4000 characters)
// Overlap: 100-200 tokens (~400-800 characters)

interface ChunkConfig {
  chunkSize: 1000;      // tokens
  chunkOverlap: 200;    // tokens
  minChunkSize: 100;    // skip very small chunks
}
```

**Why these numbers:**
- 1000 tokens = ~4 paragraphs (good semantic unit)
- 200 token overlap = preserves context across chunks
- Fits comfortably in GPT-4's context window with metadata

### 4.4 RAG Pipeline

```
1. File Upload ‚Üí Vercel Blob
2. Text Extraction (pdf-parse, docx-parser, etc.)
3. Chunking (overlap strategy)
4. Embed Each Chunk (OpenAI embeddings API)
5. Store in FileChunk table with pgvector
6. Student Query ‚Üí Embed Query
7. Vector Search (top 5-10 chunks via pgvector)
8. Build Prompt with Context
9. Call GPT-4 with context + query
10. Return Response + Source Citations
```

---

## 5. Implementation Plan: Step-by-Step

### Phase 1: Database Migration (Day 1)

**Steps:**
1. ‚úÖ Back up current database (export with `npx prisma db pull`)
2. ‚úÖ Enable pgvector extension in Neon:
   ```sql
   -- Run in Vercel Postgres dashboard or via Prisma Studio SQL editor
   CREATE EXTENSION IF NOT EXISTS vector;
   ```
3. ‚úÖ Update `prisma/schema.prisma` with new simplified schema (above)
4. ‚úÖ Delete old models from schema
5. ‚úÖ Run `npx prisma generate`
6. ‚úÖ Run `npx prisma db push` (WARNING: This will delete data!)
7. ‚úÖ Create vector index with raw SQL:
   ```sql
   CREATE INDEX ON "FileChunk" USING ivfflat (embedding vector_cosine_ops) WITH (lists = 100);
   ```
8. ‚úÖ Verify schema in Prisma Studio

**Files to modify:**
- `prisma/schema.prisma`

### Phase 2: Remove Old Features (Day 1-2)

**Delete these directories:**
```bash
rm -rf app/(teacher)/games
rm -rf app/(teacher)/library
rm -rf app/(teacher)/classes/[classId]/lessons
rm -rf app/(teacher)/upload
rm -rf app/(student)/history  # Keep if you want student to see own chats
```

**Delete these action files:**
```bash
rm app/actions/flashcard.ts
rm app/actions/worksheet.ts
rm app/actions/summary.ts
rm app/actions/packet.ts
rm app/actions/lesson.ts
rm app/actions/pdf.ts  # Will replace with fileUpload.ts
```

**Delete these lib files:**
```bash
rm -rf lib/processors/  # Old PDF/AI generation logic
```

**Keep these files:**
- `app/actions/auth.ts` ‚úÖ
- `app/actions/class.ts` ‚úÖ (modify later)
- `app/actions/chatHistory.ts` ‚úÖ (modify later)
- `lib/auth.ts` ‚úÖ
- `lib/db.ts` ‚úÖ
- `lib/blob.ts` ‚úÖ

### Phase 3: OpenAI Setup (Day 2)

**3.1 Install dependencies:**
```bash
npm install openai
npm install pdf-parse  # Keep for PDFs
npm install mammoth    # For DOCX files
npm install langchain @langchain/openai  # Optional: for advanced chunking
```

**3.2 Add environment variable:**
```bash
# .env and .env.local
OPENAI_API_KEY=sk-...
```

**3.3 Create OpenAI client:**
```typescript
// lib/openai.ts
import OpenAI from 'openai';

export const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY!,
});

// Embedding function
export async function embedText(text: string): Promise<number[]> {
  const response = await openai.embeddings.create({
    model: 'text-embedding-3-small',
    input: text,
    encoding_format: 'float',
  });
  return response.data[0].embedding;
}

// Chat function with RAG context
export async function chatWithContext(
  query: string,
  context: string[],
  conversationHistory: { role: 'user' | 'assistant'; content: string }[]
) {
  const systemPrompt = `You are a helpful AI tutor. Answer the student's question using ONLY the provided context from class materials. If the context doesn't contain the answer, say so.

Context:
${context.join('\n\n---\n\n')}`;

  const response = await openai.chat.completions.create({
    model: 'gpt-4o-mini',
    messages: [
      { role: 'system', content: systemPrompt },
      ...conversationHistory,
      { role: 'user', content: query },
    ],
    temperature: 0.7,
    max_tokens: 1000,
  });

  return response.choices[0].message.content;
}
```

### Phase 4: File Processing Pipeline (Day 3-4)

**4.1 Create text extraction utilities:**

```typescript
// lib/extractors/text-extractor.ts
import pdf from 'pdf-parse';
import mammoth from 'mammoth';

export async function extractText(
  buffer: Buffer,
  mimeType: string
): Promise<string> {
  switch (mimeType) {
    case 'application/pdf':
      const pdfData = await pdf(buffer);
      return pdfData.text;

    case 'application/vnd.openxmlformats-officedocument.wordprocessingml.document':
      const docxResult = await mammoth.extractRawText({ buffer });
      return docxResult.value;

    case 'text/plain':
      return buffer.toString('utf-8');

    default:
      throw new Error(`Unsupported file type: ${mimeType}`);
  }
}
```

**4.2 Create chunking utility:**

```typescript
// lib/chunking/text-chunker.ts
export interface Chunk {
  content: string;
  index: number;
  metadata?: {
    startChar: number;
    endChar: number;
  };
}

export function chunkText(
  text: string,
  chunkSize: number = 4000,  // ~1000 tokens
  overlap: number = 800      // ~200 tokens
): Chunk[] {
  const chunks: Chunk[] = [];
  let startIndex = 0;
  let chunkIndex = 0;

  while (startIndex < text.length) {
    const endIndex = Math.min(startIndex + chunkSize, text.length);
    const content = text.slice(startIndex, endIndex);

    // Skip very small chunks
    if (content.trim().length >= 100) {
      chunks.push({
        content: content.trim(),
        index: chunkIndex,
        metadata: {
          startChar: startIndex,
          endChar: endIndex,
        },
      });
      chunkIndex++;
    }

    startIndex += chunkSize - overlap;
  }

  return chunks;
}
```

**4.3 Create file upload action:**

```typescript
// app/actions/fileUpload.ts
'use server'

import { auth } from '@/lib/auth';
import { db } from '@/lib/db';
import { put } from '@vercel/blob';
import { extractText } from '@/lib/extractors/text-extractor';
import { chunkText } from '@/lib/chunking/text-chunker';
import { embedText } from '@/lib/openai';

export async function uploadClassFile(classId: string, formData: FormData) {
  const session = await auth();
  if (!session?.user || session.user.role !== 'TEACHER') {
    return { error: 'Unauthorized' };
  }

  // Verify class ownership
  const classRecord = await db.class.findUnique({
    where: { id: classId },
  });
  if (!classRecord || classRecord.teacherId !== session.user.id) {
    return { error: 'Class not found or unauthorized' };
  }

  const file = formData.get('file') as File;
  if (!file) {
    return { error: 'No file provided' };
  }

  // Upload to Vercel Blob
  const blob = await put(`class-files/${classId}/${file.name}`, file, {
    access: 'public',
    addRandomSuffix: true,
  });

  // Create file record
  const classFile = await db.classFile.create({
    data: {
      classId,
      fileName: file.name,
      fileType: file.type,
      fileSize: file.size,
      blobUrl: blob.url,
      uploadedBy: session.user.id,
      status: 'PENDING',
    },
  });

  // Process asynchronously (background job)
  processFileInBackground(classFile.id).catch(console.error);

  return { success: true, fileId: classFile.id };
}

async function processFileInBackground(fileId: string) {
  try {
    // Update status
    await db.classFile.update({
      where: { id: fileId },
      data: { status: 'PROCESSING' },
    });

    // Get file
    const file = await db.classFile.findUnique({
      where: { id: fileId },
    });
    if (!file) throw new Error('File not found');

    // Download from blob
    const response = await fetch(file.blobUrl);
    const buffer = Buffer.from(await response.arrayBuffer());

    // Extract text
    const text = await extractText(buffer, file.fileType);

    // Chunk text
    const chunks = chunkText(text);

    // Embed and store chunks (batch processing)
    for (const chunk of chunks) {
      const embedding = await embedText(chunk.content);

      await db.$executeRaw`
        INSERT INTO "FileChunk" (id, "fileId", "classId", content, embedding, "chunkIndex", metadata, "createdAt")
        VALUES (
          gen_random_uuid()::text,
          ${fileId},
          ${file.classId},
          ${chunk.content},
          ${embedding}::vector,
          ${chunk.index},
          ${JSON.stringify(chunk.metadata)}::jsonb,
          NOW()
        )
      `;
    }

    // Update status
    await db.classFile.update({
      where: { id: fileId },
      data: { status: 'COMPLETED' },
    });

  } catch (error) {
    console.error('File processing error:', error);
    await db.classFile.update({
      where: { id: fileId },
      data: {
        status: 'FAILED',
        errorMessage: error instanceof Error ? error.message : 'Unknown error',
      },
    });
  }
}

export async function deleteClassFile(fileId: string) {
  const session = await auth();
  if (!session?.user || session.user.role !== 'TEACHER') {
    return { error: 'Unauthorized' };
  }

  // Verify ownership
  const file = await db.classFile.findUnique({
    where: { id: fileId },
    include: { class: true },
  });

  if (!file || file.class.teacherId !== session.user.id) {
    return { error: 'File not found or unauthorized' };
  }

  // Delete from blob
  await del(file.blobUrl);

  // Delete from DB (cascades to chunks)
  await db.classFile.delete({
    where: { id: fileId },
  });

  return { success: true };
}

export async function getClassFiles(classId: string) {
  const session = await auth();
  if (!session?.user) {
    return { error: 'Unauthorized' };
  }

  // Verify access (teacher owns class OR student is member)
  if (session.user.role === 'TEACHER') {
    const classRecord = await db.class.findUnique({
      where: { id: classId },
    });
    if (!classRecord || classRecord.teacherId !== session.user.id) {
      return { error: 'Unauthorized' };
    }
  } else if (session.user.role === 'STUDENT') {
    const membership = await db.classMembership.findUnique({
      where: {
        classId_userId: {
          classId,
          userId: session.user.id,
        },
      },
    });
    if (!membership) {
      return { error: 'Unauthorized' };
    }
  }

  const files = await db.classFile.findMany({
    where: { classId },
    orderBy: { createdAt: 'desc' },
    select: {
      id: true,
      fileName: true,
      fileType: true,
      fileSize: true,
      status: true,
      errorMessage: true,
      createdAt: true,
    },
  });

  return { success: true, files };
}
```

### Phase 5: RAG Chat Implementation (Day 5-6)

**5.1 Create vector search utility:**

```typescript
// lib/vectorSearch.ts
import { db } from './db';
import { embedText } from './openai';

export interface SearchResult {
  chunkId: string;
  content: string;
  similarity: number;
  fileName: string;
  fileId: string;
}

export async function searchClassVectors(
  classId: string,
  query: string,
  topK: number = 10
): Promise<SearchResult[]> {
  // Embed the query
  const queryEmbedding = await embedText(query);

  // Vector similarity search using pgvector
  const results = await db.$queryRaw<SearchResult[]>`
    SELECT
      fc.id as "chunkId",
      fc.content,
      1 - (fc.embedding <=> ${queryEmbedding}::vector) as similarity,
      cf."fileName" as "fileName",
      cf.id as "fileId"
    FROM "FileChunk" fc
    JOIN "ClassFile" cf ON fc."fileId" = cf.id
    WHERE fc."classId" = ${classId}
    ORDER BY fc.embedding <=> ${queryEmbedding}::vector
    LIMIT ${topK}
  `;

  return results;
}
```

**5.2 Create chat action:**

```typescript
// app/actions/chat.ts
'use server'

import { auth } from '@/lib/auth';
import { db } from '@/lib/db';
import { chatWithContext } from '@/lib/openai';
import { searchClassVectors } from '@/lib/vectorSearch';

export async function sendChatMessage(
  conversationId: string,
  message: string
) {
  const session = await auth();
  if (!session?.user) {
    return { error: 'Unauthorized' };
  }

  // Get conversation and verify access
  const conversation = await db.chatConversation.findUnique({
    where: { id: conversationId },
    include: {
      messages: {
        orderBy: { createdAt: 'asc' },
        take: 20,  // Last 20 messages for context
      },
      class: true,
    },
  });

  if (!conversation || conversation.userId !== session.user.id) {
    return { error: 'Conversation not found or unauthorized' };
  }

  // Save user message
  await db.chatMessage.create({
    data: {
      conversationId,
      role: 'user',
      content: message,
    },
  });

  // Search for relevant context
  const searchResults = await searchClassVectors(
    conversation.classId,
    message,
    5  // Top 5 most relevant chunks
  );

  // Build context string with source citations
  const context = searchResults.map((result, index) =>
    `[Source ${index + 1}: ${result.fileName}]\n${result.content}`
  );

  // Get conversation history for context
  const history = conversation.messages.map(msg => ({
    role: msg.role as 'user' | 'assistant',
    content: msg.content,
  }));

  // Generate AI response
  const aiResponse = await chatWithContext(message, context, history);

  // Save AI message
  const aiMessage = await db.chatMessage.create({
    data: {
      conversationId,
      role: 'assistant',
      content: aiResponse,
    },
  });

  return {
    success: true,
    message: aiMessage,
    sources: searchResults.map(r => ({
      fileName: r.fileName,
      fileId: r.fileId,
    })),
  };
}

export async function createConversation(classId: string) {
  const session = await auth();
  if (!session?.user || session.user.role !== 'STUDENT') {
    return { error: 'Unauthorized' };
  }

  // Verify student is member of class
  const membership = await db.classMembership.findUnique({
    where: {
      classId_userId: {
        classId,
        userId: session.user.id,
      },
    },
  });

  if (!membership) {
    return { error: 'Not a member of this class' };
  }

  const conversation = await db.chatConversation.create({
    data: {
      userId: session.user.id,
      classId,
      title: 'New Conversation',
    },
  });

  return { success: true, conversationId: conversation.id };
}

export async function getConversationMessages(conversationId: string) {
  const session = await auth();
  if (!session?.user) {
    return { error: 'Unauthorized' };
  }

  const conversation = await db.chatConversation.findUnique({
    where: { id: conversationId },
    include: {
      messages: {
        orderBy: { createdAt: 'asc' },
      },
    },
  });

  if (!conversation || conversation.userId !== session.user.id) {
    return { error: 'Unauthorized' };
  }

  return { success: true, messages: conversation.messages };
}
```

### Phase 6: Update Teacher UI (Day 7)

**6.1 Modify teacher class page:**

```typescript
// app/(teacher)/classes/[classId]/page.tsx
// Add new tab: "Files"

export default async function ClassPage({ params }) {
  // ... existing code ...

  return (
    <div>
      <Tabs>
        <Tab label="Students">
          {/* Existing student roster */}
        </Tab>

        <Tab label="Files">
          <FileUploadSection classId={params.classId} />
          <FileList classId={params.classId} />
        </Tab>

        <Tab label="Chat History">
          <ChatHistoryViewer classId={params.classId} />
        </Tab>
      </Tabs>
    </div>
  );
}
```

**6.2 Create file upload component:**

```typescript
// components/teacher/FileUploadSection.tsx
'use client'

import { useState } from 'react';
import { uploadClassFile } from '@/app/actions/fileUpload';

export function FileUploadSection({ classId }: { classId: string }) {
  const [uploading, setUploading] = useState(false);

  async function handleUpload(e: React.FormEvent<HTMLFormElement>) {
    e.preventDefault();
    setUploading(true);

    const formData = new FormData(e.currentTarget);
    const result = await uploadClassFile(classId, formData);

    if (result.success) {
      alert('File uploaded! Processing in background...');
      e.currentTarget.reset();
    } else {
      alert(`Error: ${result.error}`);
    }

    setUploading(false);
  }

  return (
    <form onSubmit={handleUpload} className="card bg-base-200 p-6">
      <h3 className="text-lg font-semibold mb-4">Upload Class Materials</h3>
      <div className="form-control">
        <label className="label">
          <span className="label-text">Select file (PDF, DOCX, TXT)</span>
        </label>
        <input
          type="file"
          name="file"
          accept=".pdf,.docx,.txt"
          className="file-input file-input-bordered"
          required
        />
      </div>
      <button
        type="submit"
        className="btn btn-primary mt-4"
        disabled={uploading}
      >
        {uploading ? 'Uploading...' : 'Upload File'}
      </button>
    </form>
  );
}
```

**6.3 Create file list component:**

```typescript
// components/teacher/FileList.tsx
'use client'

import { useEffect, useState } from 'react';
import { getClassFiles, deleteClassFile } from '@/app/actions/fileUpload';

export function FileList({ classId }: { classId: string }) {
  const [files, setFiles] = useState([]);
  const [loading, setLoading] = useState(true);

  useEffect(() => {
    loadFiles();
  }, [classId]);

  async function loadFiles() {
    const result = await getClassFiles(classId);
    if (result.success) {
      setFiles(result.files);
    }
    setLoading(false);
  }

  async function handleDelete(fileId: string) {
    if (!confirm('Delete this file? This will remove all associated data.')) {
      return;
    }

    const result = await deleteClassFile(fileId);
    if (result.success) {
      loadFiles();
    } else {
      alert(`Error: ${result.error}`);
    }
  }

  if (loading) return <div>Loading files...</div>;

  return (
    <div className="card bg-base-200 p-6 mt-6">
      <h3 className="text-lg font-semibold mb-4">Class Files</h3>
      <table className="table">
        <thead>
          <tr>
            <th>File Name</th>
            <th>Type</th>
            <th>Size</th>
            <th>Status</th>
            <th>Uploaded</th>
            <th>Actions</th>
          </tr>
        </thead>
        <tbody>
          {files.map(file => (
            <tr key={file.id}>
              <td>{file.fileName}</td>
              <td>{file.fileType}</td>
              <td>{(file.fileSize / 1024).toFixed(1)} KB</td>
              <td>
                <span className={`badge ${
                  file.status === 'COMPLETED' ? 'badge-success' :
                  file.status === 'FAILED' ? 'badge-error' :
                  file.status === 'PROCESSING' ? 'badge-warning' :
                  'badge-info'
                }`}>
                  {file.status}
                </span>
              </td>
              <td>{new Date(file.createdAt).toLocaleDateString()}</td>
              <td>
                <button
                  onClick={() => handleDelete(file.id)}
                  className="btn btn-sm btn-error"
                >
                  Delete
                </button>
              </td>
            </tr>
          ))}
        </tbody>
      </table>
      {files.length === 0 && (
        <p className="text-center text-gray-500 py-8">
          No files uploaded yet. Upload materials to get started!
        </p>
      )}
    </div>
  );
}
```

### Phase 7: Update Student UI (Day 8)

**7.1 Create student class page:**

```typescript
// app/(student)/classes/[classId]/page.tsx
import { ChatInterface } from '@/components/student/ChatInterface';
import { getClassFiles } from '@/app/actions/fileUpload';

export default async function StudentClassPage({ params }) {
  const filesResult = await getClassFiles(params.classId);

  return (
    <div className="container mx-auto p-6">
      <div className="grid grid-cols-1 lg:grid-cols-3 gap-6">
        {/* Files Sidebar */}
        <div className="lg:col-span-1">
          <div className="card bg-base-200 p-4">
            <h3 className="font-semibold mb-4">Class Materials</h3>
            {filesResult.success && (
              <ul className="space-y-2">
                {filesResult.files.map(file => (
                  <li key={file.id} className="text-sm">
                    üìÑ {file.fileName}
                  </li>
                ))}
              </ul>
            )}
          </div>
        </div>

        {/* Chat Interface */}
        <div className="lg:col-span-2">
          <ChatInterface classId={params.classId} />
        </div>
      </div>
    </div>
  );
}
```

**7.2 Create chat interface:**

```typescript
// components/student/ChatInterface.tsx
'use client'

import { useState, useEffect } from 'react';
import { createConversation, sendChatMessage, getConversationMessages } from '@/app/actions/chat';

export function ChatInterface({ classId }: { classId: string }) {
  const [conversationId, setConversationId] = useState<string | null>(null);
  const [messages, setMessages] = useState([]);
  const [input, setInput] = useState('');
  const [loading, setLoading] = useState(false);

  useEffect(() => {
    initConversation();
  }, [classId]);

  async function initConversation() {
    const result = await createConversation(classId);
    if (result.success) {
      setConversationId(result.conversationId);
    }
  }

  async function handleSend() {
    if (!input.trim() || !conversationId || loading) return;

    setLoading(true);
    const userMessage = input;
    setInput('');

    // Optimistic update
    setMessages(prev => [...prev, { role: 'user', content: userMessage }]);

    const result = await sendChatMessage(conversationId, userMessage);

    if (result.success) {
      setMessages(prev => [...prev, {
        role: 'assistant',
        content: result.message.content,
        sources: result.sources
      }]);
    } else {
      alert(`Error: ${result.error}`);
    }

    setLoading(false);
  }

  return (
    <div className="card bg-base-200 h-[600px] flex flex-col">
      {/* Messages */}
      <div className="flex-1 overflow-y-auto p-4 space-y-4">
        {messages.map((msg, i) => (
          <div key={i} className={`chat ${msg.role === 'user' ? 'chat-end' : 'chat-start'}`}>
            <div className="chat-bubble">
              {msg.content}
              {msg.sources && (
                <div className="text-xs mt-2 opacity-70">
                  Sources: {msg.sources.map(s => s.fileName).join(', ')}
                </div>
              )}
            </div>
          </div>
        ))}
        {loading && (
          <div className="chat chat-start">
            <div className="chat-bubble">
              <span className="loading loading-dots"></span>
            </div>
          </div>
        )}
      </div>

      {/* Input */}
      <div className="p-4 border-t">
        <div className="flex gap-2">
          <input
            type="text"
            value={input}
            onChange={(e) => setInput(e.target.value)}
            onKeyPress={(e) => e.key === 'Enter' && handleSend()}
            placeholder="Ask a question about class materials..."
            className="input input-bordered flex-1"
            disabled={loading}
          />
          <button
            onClick={handleSend}
            className="btn btn-primary"
            disabled={loading || !input.trim()}
          >
            Send
          </button>
        </div>
      </div>
    </div>
  );
}
```

### Phase 8: Chat History for Teachers (Day 9)

**Keep existing chat history viewer but simplify:**

```typescript
// app/(teacher)/classes/[classId]/insights/page.tsx
// Keep most of existing code, but:
// - Remove materialId filters (no longer exists)
// - Simplify to just show student conversations
// - Add search/filter by date, student, keywords
```

### Phase 9: Testing & Deployment (Day 10)

**9.1 Local Testing Checklist:**
- [ ] Teacher can create class
- [ ] Teacher can upload PDF, DOCX, TXT files
- [ ] Files are processed and vectorized (check FileChunk table)
- [ ] Student can join class (optional: test invite code flow)
- [ ] Student can chat and get relevant answers
- [ ] Source citations appear in chat responses
- [ ] Teacher can view student chat history
- [ ] Teacher can delete files (cascades to chunks)
- [ ] Vector search returns relevant results

**9.2 Deployment:**
```bash
# 1. Commit changes
git add .
git commit -m "Simplified RAG platform implementation"

# 2. Deploy to Vercel
vercel --prod

# 3. Ensure environment variables are set:
# - DATABASE_URL (Vercel Postgres)
# - OPENAI_API_KEY
# - NEXTAUTH_SECRET
# - BLOB_READ_WRITE_TOKEN
```

**9.3 Post-deployment verification:**
- [ ] Enable pgvector extension in production DB
- [ ] Create vector index in production
- [ ] Test file upload in production
- [ ] Monitor OpenAI API usage/costs
- [ ] Check Vercel Function logs for errors

---

## 6. Cost Estimation

### OpenAI Costs (Monthly for 100 students, 10 classes)

**Assumptions:**
- 50 files uploaded (500 pages total)
- ~500k tokens for embeddings (one-time per file)
- 1,000 student queries/month
- Average 5 relevant chunks per query (2,500 tokens input)
- Average 200 tokens output per response

**Breakdown:**
1. **Embeddings (one-time per file):**
   - 500k tokens √ó $0.00002 = **$0.01 per file**
   - 50 files = **$0.50 one-time**

2. **Chat completions (recurring):**
   - Input: 1,000 queries √ó 2,500 tokens √ó $0.00015 = **$0.375/month**
   - Output: 1,000 queries √ó 200 tokens √ó $0.0006 = **$0.12/month**
   - **Total: ~$0.50/month for 1,000 queries**

3. **Total first month:** $1.00
4. **Subsequent months:** $0.50/month

**Scaling:**
- 1,000 students: ~$50/month
- 10,000 students: ~$500/month

---

## 7. Future Enhancements (Post-MVP)

### Phase 2 Features:
1. **Advanced chunking** - Use LangChain's RecursiveCharacterTextSplitter for better semantic chunking
2. **Multi-modal RAG** - Extract images/tables from PDFs using GPT-4 Vision
3. **Conversation memory** - Summarize long conversations to fit context window
4. **Hybrid search** - Combine vector search with keyword search (pgvector + full-text search)
5. **Citation links** - Link to specific pages in source PDFs
6. **Analytics dashboard** - Most asked questions, common topics, student engagement

### Phase 3 Features:
1. **Fine-tuned embeddings** - Train custom embeddings for your domain
2. **Agentic RAG** - Use LangChain agents for multi-step reasoning
3. **Study guides** - Auto-generate summaries of class materials
4. **Quizzes** - Generate practice questions from materials
5. **Voice chat** - Use OpenAI Whisper + TTS for voice conversations

---

## 8. Troubleshooting Guide

### pgvector Issues

**Problem:** `extension "vector" does not exist`
```sql
-- Solution: Enable extension
CREATE EXTENSION IF NOT EXISTS vector;
```

**Problem:** Vector index not being used
```sql
-- Check query plan
EXPLAIN SELECT * FROM "FileChunk" ORDER BY embedding <=> $1::vector LIMIT 10;

-- If not using index, recreate:
DROP INDEX IF EXISTS file_chunk_embedding_idx;
CREATE INDEX file_chunk_embedding_idx ON "FileChunk" USING ivfflat (embedding vector_cosine_ops) WITH (lists = 100);
```

### OpenAI Issues

**Problem:** Rate limit errors
```typescript
// Solution: Add retry logic with exponential backoff
import { OpenAI } from 'openai';

const openai = new OpenAI({
  maxRetries: 3,
  timeout: 30000,
});
```

**Problem:** Context too large
```typescript
// Solution: Reduce number of chunks or chunk size
const searchResults = await searchClassVectors(classId, message, 3);  // Reduce from 5 to 3
```

### File Processing Issues

**Problem:** Processing timeout on large files
```typescript
// Solution: Process in smaller batches
const chunks = chunkText(text);
for (let i = 0; i < chunks.length; i += 10) {
  const batch = chunks.slice(i, i + 10);
  await Promise.all(batch.map(chunk => processChunk(chunk)));
  await new Promise(resolve => setTimeout(resolve, 1000));  // Rate limiting
}
```

---

## 9. Migration Risks & Mitigation

### High Risk: Data Loss
- **Risk:** `npx prisma db push` will delete existing data
- **Mitigation:** Export current data first, or use a new database

### Medium Risk: Breaking Changes
- **Risk:** Users/teachers may have existing workflows
- **Mitigation:** Announce changes, provide migration guide

### Low Risk: Performance
- **Risk:** Vector search may be slow on large datasets
- **Mitigation:** Use proper indexes, monitor query times

---

## 10. Final Recommendations

### ‚úÖ DO THIS:
1. Strip down existing project (faster than starting fresh)
2. Use pgvector with Vercel Postgres (simplest architecture)
3. Use OpenAI text-embedding-3-small (cost-effective)
4. Use GPT-4o-mini for chat (fast and cheap)
5. Keep auth, class management, and chat history features
6. Start with simple chunking (1000 tokens, 200 overlap)
7. Deploy to Vercel (same infrastructure)

### ‚ùå DON'T DO THIS:
1. Don't start a new Next.js project (waste of time)
2. Don't use external vector DB yet (over-engineering)
3. Don't implement complex RAG patterns (start simple)
4. Don't keep lesson/packet features (delete them)
5. Don't worry about scale yet (optimize after MVP)

---

## 11. Timeline Estimate

**Total: 8-10 days (60-80 hours)**

- Day 1-2: Database migration & cleanup (12 hours)
- Day 3-4: File processing pipeline (16 hours)
- Day 5-6: RAG chat implementation (16 hours)
- Day 7: Teacher UI updates (8 hours)
- Day 8: Student UI updates (8 hours)
- Day 9: Chat history updates (6 hours)
- Day 10: Testing & deployment (6 hours)

**Fast track (if aggressive): 5-7 days**

---

## 12. Next Steps

1. **Back up current database** (export with Prisma)
2. **Create a new git branch**: `git checkout -b rag-simplification`
3. **Enable pgvector in Neon**: Run SQL in Vercel dashboard
4. **Update Prisma schema**: Copy new schema from above
5. **Start deleting old features**: Follow Phase 2 guide
6. **Get OpenAI API key**: https://platform.openai.com/api-keys
7. **Follow implementation plan**: Phase 3 onwards

---

## 13. Questions to Answer Before Starting

1. **Do you want to keep invite codes for student enrollment?**
   - If yes: Keep InviteCode model
   - If no: Students manually added by teachers?

2. **Should students see their own chat history?**
   - If yes: Keep `app/(student)/history` route
   - If no: Only teachers see chat history

3. **File types to support initially?**
   - Recommended: PDF, DOCX, TXT
   - Later: PPTX, XLSX, images (OCR)

4. **Max file size limit?**
   - Recommended: 25MB (Vercel Function limit)
   - Vercel Blob supports up to 500MB on Pro plan

5. **How should students join classes?**
   - Option A: Invite codes (existing system)
   - Option B: Email invites
   - Option C: Manual enrollment by teacher

---

**Ready to start? Begin with Phase 1: Database Migration!**

Let me know if you have any questions or need clarification on any section.
